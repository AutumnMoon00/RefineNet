{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from user_inputs import laz_file_path, clip_folder_path\n",
    "from user_inputs import search_radius, nn_threshold, bin_count_nn\n",
    "from helper_functions import generate_bins, fraction_of_trues\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Geomatics\\\\thesis\\\\RefineNet\\\\data\\\\AHN\\\\clipped\\\\C_37EN2_clipped.LAZ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laz_file_name = laz_file_path.split(\"\\\\\")[-1].split(\".\")\n",
    "clip_laz_file_name = laz_file_name[0] + \"_clipped.\" + laz_file_name[1]\n",
    "clip_laz_path = clip_folder_path + \"\\\\\" + clip_laz_file_name\n",
    "clip_laz_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "laz = laspy.read(clip_laz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out all the available dimensions in clipped laz file\n",
    "for dimension in laz.point_format.dimensions:\n",
    "    print(dimension.name)\n",
    "print(\"\\nunique classifications in clipped region: \", np.unique(laz.classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neighbourhood search steps**\n",
    "- making a kd tree (first load the points)\n",
    "- finding the nearest points within 0.5 m radius\n",
    "    - we can first build np array (or pandas dataframe) with all the required points, classification (labels), rgb(?), intensities\n",
    "    - then use np.where to find out the distances and indexes of the neighbour points\n",
    "    - filter only those within 0.5m and look for their classifications\n",
    "    - give confidence scores to points\n",
    "    - add extra dimension to laz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the xyz values\n",
    "xyz = laz.xyz.copy()\n",
    "print(\"xyz shape: \", xyz.shape)\n",
    "# build a kd tree\n",
    "tree = KDTree(xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the classifications of points\n",
    "labels = laz.classification\n",
    "print(\"labels shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning for neighbourhood search, nobebook crashing when given all the points\n",
    "num_points = laz.header.point_count\n",
    "nn_bins = generate_bins(number=num_points, bin_count=bin_count_nn)\n",
    "print(num_points)\n",
    "print(nn_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Just implementing for one bin now*  \n",
    "- **chose 10th bin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = nn_bins[10][0], nn_bins[10][1]\n",
    "print(start, end)\n",
    "## nearest neighbours -> nn within distance r = 0.5m \n",
    "nn = tree.query_ball_point(xyz[start:end, :], r=0.5, p=2, workers=-1, return_sorted=True)\n",
    "# print(nn)\n",
    "confidence_scores = []  # to add confidence of each point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have all the neighbouring points (including itself) for a given point**\n",
    "- seperate the current point from the neighbours\n",
    "- get classification of the current point\n",
    "- get classification of the neighbour points\n",
    "- **Calculate confidences**\n",
    "    - **count the percentage of neighbour points are of same classification**\n",
    "    - **points with neighbours < threshold => we would be giving -1 confidence.. should be altered later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pts labels -> (n, 1) np array\n",
    "print(start, end)\n",
    "pts = np.arange(start, end, step=1)\n",
    "pts_vector = pts.reshape((-1, 1))\n",
    "pts_labels = np.array(labels[pts])\n",
    "pts_labels = pts_labels.reshape((-1, 1))  # reshaping it to a column vector -> easy to make comparison with neighbours\n",
    "print(\"pts_labels: \", pts_labels)\n",
    "print(\"pts_labels.shape: \", pts_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(lst) for lst in nn)\n",
    "nn_np_padded = np.array([lst + [np.nan] * (max_length - len(lst)) for lst in nn], dtype=object)  # self points should be removed\n",
    "nn_np_padded_float = nn_np_padded.astype(float)  # self points should be removed\n",
    "\n",
    "# remove the search point itself from the neighbours by creating a mask\n",
    "self_mask = (pts_vector == nn_np_padded_float)\n",
    "nn_np_padded[self_mask] = np.nan\n",
    "nn_np_padded_float[self_mask] = np.nan\n",
    "\n",
    "\n",
    "# flattening the neighbours array \n",
    "# so that it is easy to pass to labels and get the classificaitons\n",
    "nn_np_padded_flat = nn_np_padded.reshape((1, -1))\n",
    "nn_np_padded_float_flat = nn_np_padded_float.reshape((1, -1))\n",
    "# nanMask ## True when the element is nan\n",
    "nn_np_padded_float_flat_nanMask = np.isnan(nn_np_padded_float_flat)\n",
    "nn_np_padded_Mask = ~np.isnan(nn_np_padded_float)\n",
    "\n",
    "# replacing all the nan's with -1 index as a placeholder, later we can use mask again to filter them out \n",
    "nn_np_padded_flat[nn_np_padded_float_flat_nanMask] = -1  # replacing all the nan's with -1, now we can use this variable to get neighbours classifications\n",
    "nn_labels_flat_pHold = labels[list(nn_np_padded_flat[0])]\n",
    "nn_labels_flat_pHold = np.array(nn_labels_flat_pHold)\n",
    "# nn_labels_flat = nn_labels_flat_pHold *  ~nn_np_padded_float_flat_nanMask\n",
    "nn_labels_flat = nn_labels_flat_pHold.copy()\n",
    "nn_labels_flat_float = nn_labels_flat.astype(float)\n",
    "nn_labels_flat_float[nn_np_padded_float_flat_nanMask[0]] = np.nan\n",
    "\n",
    "# 2d array => no more flattened\n",
    "nn_labels_float = nn_labels_flat_float.reshape((nn_np_padded.shape[0], -1))\n",
    "# indetifying \n",
    "\n",
    "print(nn_np_padded_float_flat_nanMask)\n",
    "print(nn_labels_flat_pHold)\n",
    "# print(nn_labels_flat_pHold.reshape((nn_np_padded.shape[0], -1)))\n",
    "print(\"nn_labels_float: \", nn_labels_float)\n",
    "print(\"nn_labels_float.shape: \", nn_labels_float.shape)\n",
    "print(\"nn_labels_float[0]: \", nn_labels_float[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confidence = (label_match_count) / (neighbour_count)**\n",
    "1. get match count\n",
    "2. get neighbour count\n",
    "3. calculate confidence\n",
    "\n",
    "**After**\n",
    "1. get threshold mask\n",
    "2. less than 5 threshold number of neighbours, give confidence of -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. compare pts_labels with nn_labels\n",
    "match_pts_nn_bool = (pts_labels == nn_labels_float)\n",
    "match_pts_nn_num = np.sum(match_pts_nn_bool, axis=1, keepdims=True) # number of points that match\n",
    "print(\"match_pts_nn_bool[0]: \", match_pts_nn_bool[0])\n",
    "print(\"match_pts_nn_num[0]: \", match_pts_nn_num[0])\n",
    "\n",
    "print(\"nn_np_padded_Mask[0]: \\n\", nn_np_padded_Mask[0])\n",
    "\n",
    "# 2. nn_count, create nn mask to filter out the points which are not surrounded by many points\n",
    "nn_count = np.sum(nn_np_padded_Mask, axis=1, keepdims=True)\n",
    "nn_threshold_mask = (nn_count < nn_threshold)\n",
    "\n",
    "print(\"nn_threshold: \", nn_threshold_mask)\n",
    "\n",
    "print(\"nn_count[0]: \", nn_count[0])\n",
    "print(\"nn_count: \", nn_count)\n",
    "print(\"nn_count.max: \", np.max(nn_count))\n",
    "\n",
    "# # 3. confidence\n",
    "# confidences = \n",
    "# confidence_from_nn_2 = np.divide(match_pts_nn_num, nn_count, out=confidences, where=)\n",
    "confidence_from_nn = match_pts_nn_num / nn_count\n",
    "confidence_from_nn[nn_threshold_mask] = -1\n",
    "print(\"confidence_from_nn: \", confidence_from_nn)\n",
    "print(\"min confidence: \", np.min(confidence_from_nn, axis=0))\n",
    "print(\"max confidence: \", np.max(confidence_from_nn, axis=0))\n",
    "# print(\"min confidence: \", np.nanmin(confidence_from_nn, axis=0))\n",
    "# print(\"max confidence: \", np.nanmax(confidence_from_nn, axis=0))\n",
    "idx_min_confidence = np.where(confidence_from_nn == np.min(confidence_from_nn))\n",
    "\n",
    "# no neighbours points\n",
    "idxs_no_nn = np.where(confidence_from_nn == np.nan)\n",
    "print(f\"idxs_no_nn: {idxs_no_nn}\")\n",
    "\n",
    "# print(\"id with least confidence: \", idx_min_confidence)\n",
    "# print(\"neighbors of least confident point: \", nn_np_padded[idx_min_confidence[0]])\n",
    "# print(\"least confident point label: \", pts_labels[idx_min_confidence[0]])\n",
    "# print(\"neightbours labels of least confident point: \", nn_labels_float[idx_min_confidence[0]])\n",
    "\n",
    "\n",
    "\n",
    "# get the confidence scores of pts\n",
    "# confidence = match_count / nn_count\n",
    "# 1. get match_count\n",
    "# 2. get nn_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "current = start\n",
    "for N in nn:\n",
    "    pt_label = labels[current]\n",
    "    # print(f\"pt: {current}, label: {pt_label}\")\n",
    "    # print(f\"N len: {len(N)}, N list: {N}\")\n",
    "    ## removing the point itself from the \n",
    "    if current in N:\n",
    "        N.remove(current)\n",
    "    # print(f\"N len: {len(N)}, N list: {N}\")\n",
    "    N_count = len(N)  # number of neighbours within r (0.50m)\n",
    "    N_labels = labels[N]\n",
    "    # print(f\"\\tN_labels: {N_labels}\")\n",
    "    \n",
    "    N_match_bool = pt_label == N_labels\n",
    "    # print(f\"match: {N_match_bool}\")\n",
    "    # calculating confidence from neighbours\n",
    "    confidence_from_N = fraction_of_trues(N_match_bool)\n",
    "    # print(f\"\\tlabel confidence: {confidence_from_N}\")\n",
    "\n",
    "    # confidence should be altered later\n",
    "\n",
    "    current += 1\n",
    "    # break\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time_seconds = end_time - start_time\n",
    "elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "print(f\"Elapsed time: {elapsed_time_minutes:.4f} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Should implement this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin in nn_bins:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USELESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(lst) for lst in nn)\n",
    "print(\"max_length: \", max_length)\n",
    "nn_np_padded = np.array([lst + [np.nan] * (max_length - len(lst)) for lst in nn], dtype=object)\n",
    "nn_np_padded_float = nn_np_padded.astype(float)\n",
    "\n",
    "nn_np_padded_flat = nn_np_padded.reshape((1, -1))\n",
    "nn_np_padded_float_flat = nn_np_padded_float.reshape((1, -1))\n",
    "# mask\n",
    "nn_np_padded_float_flat_nanMask = np.isnan(nn_np_padded_float_flat)\n",
    "\n",
    "print(nn_np_padded_float_flat_nanMask)\n",
    "\n",
    "nn_np_padded_flat[nn_np_padded_float_flat_nanMask] = -1\n",
    "print(nn_np_padded_flat)\n",
    "print(nn_np_padded_flat.shape)\n",
    "# print(list(nn_np_padded_flat[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[list(nn_np_padded_flat[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "max_length = max(len(lst) for lst in nn)\n",
    "print(\"max_length: \", max_length)\n",
    "# nn_np_padded = np.array([lst + [np.nan] * (max_length - len(lst)) for lst in nn] , dtype=object)  # , dtype=object\n",
    "nn_np_padded = np.array([lst + [np.nan] * (max_length - len(lst)) for lst in nn])  # , dtype=object\n",
    "end_time = time.time()\n",
    "elapsed_time_seconds = end_time - start_time\n",
    "elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "print(f\"Elapsed time: {elapsed_time_minutes:.4f} minutes\")\n",
    "print(nn_np_padded)\n",
    "print(nn_np_padded.shape)\n",
    "# print(nn.shape)\n",
    "\n",
    "## first figure out which row (point) has maximum number of neighbours\n",
    "mask = ~np.isnan(nn_np_padded)  # bool of neighbours, true if it has neighbour\n",
    "print(mask)\n",
    "max_nn_indices = np.where(np.sum(mask, axis=1) == max_length)\n",
    "print(\"max_nn_indices: \", max_nn_indices)\n",
    "print(\"type(max_nn_indices): \", type(max_nn_indices))\n",
    "print(\"max_nn_indices[0]: \", max_nn_indices[0])\n",
    "\n",
    "print(labels[nn_np_padded[max_nn_indices[0][0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(nn))\n",
    "print(type(nn[5]))\n",
    "print(nn.shape)\n",
    "print(nn)\n",
    "# print(len(nn[0]))\n",
    "# # xyz[nn].shape\n",
    "# print(nn)\n",
    "# np.array(nn)\n",
    "# xyz[np.array(nn[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(nn[0])\n",
    "# nn\n",
    "# max_length_list = max(nn, key=len)\n",
    "# max_length_list\n",
    "print(labels[nn[5]])\n",
    "xyz[np.NaN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(laz.xyz.shape)\n",
    "print(laz.xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(lst) for lst in nn)\n",
    "nn_np_padded = np.array([lst + [np.nan] * (max_length - len(lst)) for lst in nn], dtype=object)  # self points should be removed\n",
    "nn_np_padded_float = nn_np_padded.astype(float)  # self points should be removed\n",
    "\n",
    "print(\"BEFORE: \")\n",
    "print(nn_np_padded_float[100])\n",
    "\n",
    "# remove the search point itself from the neighbours by creating a mask\n",
    "self_mask = (pts_vector == nn_np_padded_float)\n",
    "nn_np_padded[self_mask] = np.nan\n",
    "nn_np_padded_float[self_mask] = np.nan\n",
    "\n",
    "print(\"AFTER:\")\n",
    "print(nn_np_padded_float[100])\n",
    "\n",
    "\n",
    "# flattening the neighbours array \n",
    "# so that it is easy to pass to labels and get the classificaitons\n",
    "nn_np_padded_flat = nn_np_padded.reshape((1, -1))\n",
    "nn_np_padded_float_flat = nn_np_padded_float.reshape((1, -1))\n",
    "# nanMask ## True when the element is nan\n",
    "nn_np_padded_float_flat_nanMask = np.isnan(nn_np_padded_float_flat)\n",
    "nn_np_padded_Mask = ~np.isnan(nn_np_padded_float)\n",
    "\n",
    "print(\"MASK:\")\n",
    "print(nn_np_padded_Mask[100])\n",
    "\n",
    "# replacing all the nan's with -1 index as a placeholder, later we can use mask again to filter them out \n",
    "nn_np_padded_flat[nn_np_padded_float_flat_nanMask] = -1  # replacing all the nan's with -1, now we can use this variable to get neighbours classifications\n",
    "nn_labels_flat_pHold = labels[list(nn_np_padded_flat[0])]\n",
    "nn_labels_flat_pHold = np.array(nn_labels_flat_pHold)\n",
    "# nn_labels_flat = nn_labels_flat_pHold *  ~nn_np_padded_float_flat_nanMask\n",
    "nn_labels_flat = nn_labels_flat_pHold.copy()\n",
    "nn_labels_flat_float = nn_labels_flat.astype(float)\n",
    "nn_labels_flat_float[nn_np_padded_float_flat_nanMask[0]] = np.nan\n",
    "\n",
    "# 2d array => no more flattened\n",
    "nn_labels_float = nn_labels_flat_float.reshape((nn_np_padded.shape[0], -1))\n",
    "# indetifying \n",
    "\n",
    "# print(nn_np_padded_float_flat_nanMask)\n",
    "# print(nn_labels_flat_pHold)\n",
    "# # print(nn_labels_flat_pHold.reshape((nn_np_padded.shape[0], -1)))\n",
    "# print(\"nn_labels_float: \", nn_labels_float)\n",
    "# print(\"nn_labels_float.shape: \", nn_labels_float.shape)\n",
    "print(\"CHECK:\")\n",
    "print(nn_labels_float[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
